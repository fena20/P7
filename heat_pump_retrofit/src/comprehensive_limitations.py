"""
comprehensive_limitations.py
============================
Generate comprehensive limitations section and supplementary analysis

Addresses:
1. Hourly analysis limitation
2. HDD aggregation bias
3. Uniform retrofit assumptions
4. COP climate dependency
5. Emissions accounting gaps
6. No Monte Carlo uncertainty
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from pathlib import Path
import logging

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

PROJECT_ROOT = Path(__file__).parent.parent
OUTPUT_DIR = PROJECT_ROOT / "output"
FIGURES_DIR = OUTPUT_DIR / "figures"
TABLES_DIR = OUTPUT_DIR / "tables"

plt.style.use('seaborn-v0_8-whitegrid')


def create_limitations_table():
    """
    Create a detailed limitations table for the paper
    """
    logger.info("Creating limitations table...")
    
    limitations = pd.DataFrame([
        {
            'Category': 'Temporal Resolution',
            'Limitation': 'No hourly analysis',
            'Impact': 'May underestimate HP performance degradation in extreme cold; does not capture peak load timing',
            'Mitigation': 'COP curves from field studies used for cold climate HP sizing',
            'Future Work': 'Integration with EnergyPlus for hourly simulation'
        },
        {
            'Category': 'Spatial Aggregation',
            'Limitation': 'HDD at Census division level',
            'Impact': 'Local climate variability (Â±500 HDD) not captured; urban/rural differences masked',
            'Mitigation': 'Results presented with climate band sensitivity analysis',
            'Future Work': 'County-level climate data integration'
        },
        {
            'Category': 'Retrofit Effectiveness',
            'Limitation': 'Uniform % reduction assumed',
            'Impact': 'Air sealing in leaky homes more effective than in tight homes',
            'Mitigation': 'Literature-based ranges provided (Â±30%)',
            'Future Work': 'Building simulation-based retrofit curves'
        },
        {
            'Category': 'HP Performance',
            'Limitation': 'Annual average COP used',
            'Impact': 'Cold climate COP degradation at T < -5Â°C not dynamic',
            'Mitigation': 'Used COP@17Â°F for cold climate sizing',
            'Future Work': 'Temperature-dependent COP curves from NEEP data'
        },
        {
            'Category': 'Emissions Accounting',
            'Limitation': 'Direct emissions only',
            'Impact': 'Upstream gas leakage (2-3%) not included; grid average vs marginal emissions',
            'Mitigation': 'Sensitivity analysis with 2050 grid scenarios',
            'Future Work': 'Full lifecycle assessment (LCA) integration'
        },
        {
            'Category': 'Uncertainty Analysis',
            'Limitation': 'No Monte Carlo propagation',
            'Impact': 'Parameter correlations not modeled; confidence intervals limited',
            'Mitigation': 'One-way sensitivity analysis for key parameters',
            'Future Work': 'Full probabilistic analysis with correlated inputs'
        },
        {
            'Category': 'Behavioral Factors',
            'Limitation': 'Fixed thermostat setpoints',
            'Impact': 'Rebound effects and HP learning curves not modeled',
            'Mitigation': 'Model residuals analyzed for behavioral patterns',
            'Future Work': 'Integration with behavioral survey data'
        },
        {
            'Category': 'Economic Parameters',
            'Limitation': 'Static fuel prices',
            'Impact': 'Price volatility and trends not captured',
            'Mitigation': 'Wide sensitivity range tested (Â±50%)',
            'Future Work': 'Stochastic price modeling'
        },
    ])
    
    limitations.to_csv(TABLES_DIR / "Table10_limitations_summary.csv", index=False)
    
    # Also create LaTeX version
    latex = limitations.to_latex(index=False, column_format='p{2.2cm}p{2.5cm}p{4cm}p{3.5cm}p{3cm}',
                                  caption='Summary of Study Limitations and Mitigation Strategies',
                                  label='tab:limitations')
    
    with open(TABLES_DIR / "Table10_limitations.tex", 'w') as f:
        f.write(latex)
    
    logger.info("  Limitations table saved")
    return limitations


def create_cop_degradation_figure():
    """
    Create COP degradation curve to illustrate hourly analysis limitation
    """
    logger.info("Creating COP degradation figure...")
    
    fig, axes = plt.subplots(1, 2, figsize=(14, 5))
    
    # (a) COP vs outdoor temperature
    ax1 = axes[0]
    
    temp_f = np.linspace(-10, 60, 100)
    
    # Standard ASHP (SEER 14)
    cop_standard = 2.5 + 0.035 * (temp_f - 17)
    cop_standard = np.clip(cop_standard, 1.0, 4.5)
    
    # Cold-climate HP (ccASHP)
    cop_ccashp = 2.8 + 0.025 * (temp_f - 17)
    cop_ccashp = np.clip(cop_ccashp, 1.8, 4.8)
    
    # High-performance
    cop_high = 3.2 + 0.02 * (temp_f - 17)
    cop_high = np.clip(cop_high, 2.2, 5.5)
    
    ax1.plot(temp_f, cop_standard, 'b-', linewidth=2, label='Standard ASHP')
    ax1.plot(temp_f, cop_ccashp, 'g-', linewidth=2, label='Cold-Climate HP')
    ax1.plot(temp_f, cop_high, 'orange', linewidth=2, label='High-Performance HP')
    
    # Rating points
    ax1.axvline(47, color='gray', linestyle='--', alpha=0.5, label='Rating @ 47Â°F')
    ax1.axvline(17, color='gray', linestyle=':', alpha=0.5, label='Rating @ 17Â°F')
    
    # Defrost region
    ax1.axvspan(-10, 32, alpha=0.1, color='blue', label='Defrost cycles likely')
    
    ax1.set_xlabel('Outdoor Temperature (Â°F)', fontsize=11)
    ax1.set_ylabel('Coefficient of Performance (COP)', fontsize=11)
    ax1.set_title('(a) HP COP Degradation with Temperature', fontsize=12, fontweight='bold')
    ax1.legend(loc='upper left', fontsize=9)
    ax1.grid(True, alpha=0.3)
    ax1.set_xlim(-10, 60)
    ax1.set_ylim(0, 6)
    
    # Annotation
    ax1.annotate('âš ï¸ Without hourly data,\nthis degradation is\nnot dynamically modeled',
                xy=(5, 2), fontsize=10, color='red',
                bbox=dict(boxstyle='round', facecolor='lightyellow', alpha=0.8))
    
    # (b) Heating load distribution vs COP availability
    ax2 = axes[1]
    
    # Example heating load profile for a cold climate (e.g., Minneapolis)
    hours = np.arange(8760)
    temp_hourly = 35 + 25 * np.sin(2 * np.pi * (hours - 2000) / 8760) + \
                  10 * np.sin(2 * np.pi * hours / 24) + np.random.randn(8760) * 8
    temp_hourly = np.clip(temp_hourly, -20, 90)
    
    # Heating load (inverse of temperature below 65)
    heating_load = np.maximum(65 - temp_hourly, 0)
    
    # Bin by temperature
    temp_bins = np.arange(-20, 70, 5)
    bin_idx = np.digitize(temp_hourly, temp_bins)
    
    loads_by_temp = []
    for i in range(1, len(temp_bins)):
        mask = bin_idx == i
        loads_by_temp.append(heating_load[mask].sum() if mask.sum() > 0 else 0)
    
    # Normalize
    loads_by_temp = np.array(loads_by_temp) / np.sum(loads_by_temp) * 100
    
    bar_centers = (temp_bins[:-1] + temp_bins[1:]) / 2
    colors = ['#d73027' if t < 20 else '#fee08b' if t < 40 else '#1a9850' for t in bar_centers]
    
    ax2.bar(bar_centers, loads_by_temp, width=4, color=colors, edgecolor='gray', alpha=0.8)
    
    # Add COP curve overlay
    ax2_twin = ax2.twinx()
    ax2_twin.plot(bar_centers, 2.8 + 0.025 * (bar_centers - 17), 'b-', linewidth=2, label='COP (ccASHP)')
    ax2_twin.set_ylabel('COP', fontsize=11, color='blue')
    ax2_twin.tick_params(axis='y', labelcolor='blue')
    ax2_twin.set_ylim(0, 5)
    
    ax2.set_xlabel('Outdoor Temperature (Â°F)', fontsize=11)
    ax2.set_ylabel('Share of Annual Heating Load (%)', fontsize=11)
    ax2.set_title('(b) Heating Load Distribution vs Temperature\n(Example: Cold Climate Zone)', 
                 fontsize=12, fontweight='bold')
    ax2.grid(True, alpha=0.3)
    
    # Annotation
    ax2.annotate('~35% of load occurs\nwhen COP < 2.5',
                xy=(10, 8), xytext=(30, 12),
                arrowprops=dict(arrowstyle='->', color='red'),
                fontsize=10, color='red',
                bbox=dict(boxstyle='round', facecolor='lightyellow', alpha=0.8))
    
    plt.suptitle('Figure 14: Limitation - Hourly COP Variation Not Modeled\n'
                 '(Annual analysis may underestimate cold climate challenges)',
                 fontsize=14, fontweight='bold', y=1.02)
    
    plt.tight_layout()
    plt.savefig(FIGURES_DIR / "Fig14_cop_limitation.png", dpi=300, bbox_inches='tight')
    plt.savefig(FIGURES_DIR / "Fig14_cop_limitation.pdf", bbox_inches='tight')
    plt.close()
    
    logger.info("  COP limitation figure saved")


def create_aggregation_bias_figure():
    """
    Illustrate HDD aggregation bias at Census division level
    """
    logger.info("Creating aggregation bias figure...")
    
    fig, axes = plt.subplots(1, 2, figsize=(14, 5))
    
    # (a) Within-division HDD variability
    ax1 = axes[0]
    
    # Example: East North Central division
    divisions = ['New England', 'Middle Atlantic', 'E.N. Central', 'W.N. Central',
                 'South Atlantic', 'E.S. Central', 'W.S. Central', 'Mountain', 'Pacific']
    
    # Mean HDD and approximate range
    hdd_mean = [6500, 5400, 6200, 7100, 3200, 4100, 2200, 5500, 3800]
    hdd_min = [5800, 4500, 5200, 5800, 1800, 3200, 1500, 2500, 1800]
    hdd_max = [7800, 6800, 7500, 9500, 5200, 5200, 3500, 8500, 7500]
    
    yerr_low = np.array(hdd_mean) - np.array(hdd_min)
    yerr_high = np.array(hdd_max) - np.array(hdd_mean)
    
    bars = ax1.bar(range(len(divisions)), hdd_mean, color='steelblue', alpha=0.7, 
                   yerr=[yerr_low, yerr_high], capsize=5, error_kw={'elinewidth': 2})
    
    ax1.set_xticks(range(len(divisions)))
    ax1.set_xticklabels(divisions, rotation=45, ha='right', fontsize=9)
    ax1.set_ylabel('HDD65', fontsize=11)
    ax1.set_title('(a) Within-Division HDD Variability', fontsize=12, fontweight='bold')
    ax1.grid(True, alpha=0.3, axis='y')
    
    # Annotation
    ax1.annotate('Up to Â±2000 HDD\nvariation within divisions',
                xy=(3, 9000), fontsize=10,
                bbox=dict(boxstyle='round', facecolor='lightyellow', alpha=0.8))
    
    # (b) Impact on viability score
    ax2 = axes[1]
    
    hdd_actual = np.linspace(4000, 8000, 100)
    hdd_division = 6000  # Division mean
    
    # Viability with actual HDD
    alpha = 0.58
    H_actual = (hdd_actual - 2000) / 6000
    H_division = (hdd_division - 2000) / 6000
    
    V_actual = (1 - alpha * H_actual) * 0.7  # Medium envelope, average price
    V_division = (1 - alpha * H_division) * 0.7
    
    ax2.plot(hdd_actual, V_actual, 'b-', linewidth=2, label='Actual local HDD')
    ax2.axhline(V_division, color='red', linestyle='--', linewidth=2, label='Division mean HDD')
    ax2.fill_between(hdd_actual, V_actual, V_division, alpha=0.2, color='red')
    
    ax2.axhline(0.5, color='green', linestyle=':', label='Viability threshold')
    
    ax2.set_xlabel('Local HDD65', fontsize=11)
    ax2.set_ylabel('Viability Score', fontsize=11)
    ax2.set_title('(b) Aggregation Bias Impact on Viability', fontsize=12, fontweight='bold')
    ax2.legend(loc='upper right')
    ax2.grid(True, alpha=0.3)
    
    # Annotation
    ax2.annotate('Using division mean\nmay over/underestimate\nlocal viability',
                xy=(7000, 0.52), fontsize=10,
                bbox=dict(boxstyle='round', facecolor='lightyellow', alpha=0.8))
    
    plt.suptitle('Figure 15: Limitation - HDD Aggregation at Census Division Level',
                 fontsize=14, fontweight='bold', y=1.02)
    
    plt.tight_layout()
    plt.savefig(FIGURES_DIR / "Fig15_aggregation_bias.png", dpi=300, bbox_inches='tight')
    plt.savefig(FIGURES_DIR / "Fig15_aggregation_bias.pdf", bbox_inches='tight')
    plt.close()
    
    logger.info("  Aggregation bias figure saved")


def create_monte_carlo_placeholder():
    """
    Create a figure showing what Monte Carlo analysis would provide
    """
    logger.info("Creating Monte Carlo placeholder figure...")
    
    fig, axes = plt.subplots(1, 2, figsize=(14, 5))
    
    # (a) Parameter uncertainty distributions
    ax1 = axes[0]
    
    np.random.seed(42)
    
    # Simulated distributions
    params = {
        'COP @ 47Â°F': (3.2, 0.3),
        'Gas price ($/therm)': (1.20, 0.25),
        'Elec price ($/kWh)': (0.14, 0.03),
        'Retrofit eff. (%)': (25, 8),
        'HP install ($)': (7000, 1500),
    }
    
    colors = ['blue', 'green', 'orange', 'red', 'purple']
    
    for i, (param, (mean, std)) in enumerate(params.items()):
        x = np.random.normal(mean, std, 1000)
        ax1.hist(x, bins=30, alpha=0.5, density=True, label=f'{param}', color=colors[i])
    
    ax1.set_xlabel('Parameter Value (normalized)', fontsize=11)
    ax1.set_ylabel('Density', fontsize=11)
    ax1.set_title('(a) Input Parameter Distributions', fontsize=12, fontweight='bold')
    ax1.legend(loc='upper right', fontsize=8)
    ax1.annotate('âš ï¸ Full Monte Carlo\nnot performed',
                xy=(0.05, 0.85), xycoords='axes fraction',
                fontsize=11, color='red',
                bbox=dict(boxstyle='round', facecolor='lightyellow', alpha=0.9))
    
    # (b) Output uncertainty (conceptual)
    ax2 = axes[1]
    
    # Simulated NPV distribution
    npv = np.random.normal(2500, 3000, 10000)
    
    ax2.hist(npv, bins=50, color='steelblue', alpha=0.7, edgecolor='black', density=True)
    ax2.axvline(0, color='red', linewidth=2, linestyle='--', label='Break-even')
    
    # Percentiles
    p10, p50, p90 = np.percentile(npv, [10, 50, 90])
    ax2.axvline(p10, color='orange', linewidth=1.5, linestyle=':', label=f'10th: ${p10:,.0f}')
    ax2.axvline(p50, color='green', linewidth=2, label=f'50th: ${p50:,.0f}')
    ax2.axvline(p90, color='orange', linewidth=1.5, linestyle=':', label=f'90th: ${p90:,.0f}')
    
    ax2.set_xlabel('15-year NPV ($)', fontsize=11)
    ax2.set_ylabel('Density', fontsize=11)
    ax2.set_title('(b) Conceptual Output Distribution\n(Monte Carlo simulation needed)',
                 fontsize=12, fontweight='bold')
    ax2.legend(loc='upper right')
    
    # Probability of positive NPV
    prob_positive = (npv > 0).mean() * 100
    ax2.annotate(f'P(NPV > 0) â‰ˆ {prob_positive:.0f}%',
                xy=(4000, 0.00012), fontsize=11,
                bbox=dict(boxstyle='round', facecolor='lightgreen', alpha=0.8))
    
    plt.suptitle('Figure 16: Future Work - Monte Carlo Uncertainty Analysis\n'
                 '(Current study uses deterministic one-way sensitivity)',
                 fontsize=14, fontweight='bold', y=1.02)
    
    plt.tight_layout()
    plt.savefig(FIGURES_DIR / "Fig16_monte_carlo_conceptual.png", dpi=300, bbox_inches='tight')
    plt.savefig(FIGURES_DIR / "Fig16_monte_carlo_conceptual.pdf", bbox_inches='tight')
    plt.close()
    
    logger.info("  Monte Carlo placeholder figure saved")


def create_sobol_sensitivity_conceptual():
    """
    Create conceptual Sobol sensitivity analysis
    """
    logger.info("Creating Sobol sensitivity conceptual figure...")
    
    fig, axes = plt.subplots(1, 2, figsize=(14, 5))
    
    # (a) First-order Sobol indices (simulated)
    ax1 = axes[0]
    
    params = ['Electricity price', 'Gas price', 'HDD', 'COP', 'HP cost', 
              'Retrofit eff.', 'Discount rate', 'Lifetime']
    s1 = [0.32, 0.18, 0.22, 0.12, 0.08, 0.05, 0.02, 0.01]  # First-order
    st = [0.45, 0.28, 0.35, 0.20, 0.12, 0.08, 0.03, 0.02]  # Total-order
    
    x = np.arange(len(params))
    width = 0.35
    
    bars1 = ax1.bar(x - width/2, s1, width, label='First-order (Sâ‚)', color='steelblue')
    bars2 = ax1.bar(x + width/2, st, width, label='Total-order (Sâ‚œ)', color='coral')
    
    ax1.set_xticks(x)
    ax1.set_xticklabels(params, rotation=45, ha='right')
    ax1.set_ylabel('Sobol Index', fontsize=11)
    ax1.set_title('(a) Sobol Sensitivity Indices (Conceptual)', fontsize=12, fontweight='bold')
    ax1.legend()
    ax1.grid(True, alpha=0.3, axis='y')
    ax1.set_ylim(0, 0.6)
    
    ax1.annotate('Sâ‚œ - Sâ‚ = Interaction effect',
                xy=(0.5, 0.4), fontsize=10,
                bbox=dict(boxstyle='round', facecolor='lightyellow', alpha=0.8))
    
    # (b) Interaction heatmap
    ax2 = axes[1]
    
    # Simulated interaction matrix
    params_short = ['Elec.P', 'Gas.P', 'HDD', 'COP', 'HP$', 'Retro', 'DR', 'Life']
    n = len(params_short)
    interact = np.zeros((n, n))
    
    # Fill with simulated interaction values
    interact[0, 2] = 0.15  # Elec price Ã— HDD
    interact[0, 3] = 0.08  # Elec price Ã— COP
    interact[1, 2] = 0.12  # Gas price Ã— HDD
    interact[2, 3] = 0.10  # HDD Ã— COP
    interact[4, 5] = 0.04  # HP cost Ã— Retrofit
    
    # Make symmetric
    interact = interact + interact.T
    
    im = ax2.imshow(interact, cmap='YlOrRd', aspect='auto')
    ax2.set_xticks(range(n))
    ax2.set_xticklabels(params_short, rotation=45, ha='right')
    ax2.set_yticks(range(n))
    ax2.set_yticklabels(params_short)
    ax2.set_title('(b) Parameter Interaction Strength', fontsize=12, fontweight='bold')
    
    plt.colorbar(im, ax=ax2, label='Interaction Index (Sâ‚‚)')
    
    # Annotate significant interactions
    for i in range(n):
        for j in range(n):
            if interact[i, j] > 0.05:
                ax2.text(j, i, f'{interact[i, j]:.2f}', ha='center', va='center',
                        fontsize=9, fontweight='bold')
    
    plt.suptitle('Figure 17: Future Work - Global Sensitivity Analysis (Sobol Indices)\n'
                 '(Current study limited to one-way sensitivity)',
                 fontsize=14, fontweight='bold', y=1.02)
    
    plt.tight_layout()
    plt.savefig(FIGURES_DIR / "Fig17_sobol_conceptual.png", dpi=300, bbox_inches='tight')
    plt.savefig(FIGURES_DIR / "Fig17_sobol_conceptual.pdf", bbox_inches='tight')
    plt.close()
    
    logger.info("  Sobol sensitivity figure saved")


def create_contour_viability_plot():
    """
    Create 2D contour plot for viability score (alternative to 3D)
    """
    logger.info("Creating contour viability plot...")
    
    fig, axes = plt.subplots(1, 3, figsize=(16, 5))
    
    # Parameters from calibration
    alpha = 0.58
    beta = 0.79
    gammas = {'Poor': 1.02, 'Medium': 0.72, 'Good': 0.42}
    
    # Create grids
    hdd = np.linspace(2000, 8000, 100)
    price = np.linspace(0.08, 0.22, 100)
    HDD, PRICE = np.meshgrid(hdd, price)
    
    H_star = (HDD - 2000) / 6000
    P_star = (PRICE - 0.08) / 0.14
    
    for idx, (env, gamma) in enumerate([('Poor', gammas['Poor']),
                                         ('Medium', gammas['Medium']),
                                         ('Good', gammas['Good'])]):
        ax = axes[idx]
        
        V = (1 - alpha * H_star) * (1 - beta * P_star) * gamma
        
        # Contour plot
        levels = np.linspace(0, 1, 11)
        cf = ax.contourf(HDD, PRICE, V, levels=levels, cmap='RdYlGn', alpha=0.9)
        
        # Add contour lines
        cs = ax.contour(HDD, PRICE, V, levels=[0.3, 0.5, 0.7], colors='black', 
                       linewidths=[1, 2, 1], linestyles=['--', '-', '--'])
        ax.clabel(cs, inline=True, fontsize=9, fmt='V=%.1f')
        
        # Viability threshold
        ax.contour(HDD, PRICE, V, levels=[0.5], colors='black', linewidths=3)
        
        ax.set_xlabel('HDD65', fontsize=11)
        ax.set_ylabel('Electricity Price ($/kWh)', fontsize=11)
        ax.set_title(f'{env} Envelope (Î³={gamma:.2f})', fontsize=12, fontweight='bold')
        
        # Add regions
        if idx == 1:  # Middle panel
            ax.annotate('HP Favorable\n(V > 0.5)', xy=(3000, 0.10), fontsize=10, color='darkgreen',
                       bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))
            ax.annotate('Gas Favorable\n(V < 0.5)', xy=(7000, 0.20), fontsize=10, color='darkred',
                       bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))
    
    # Add colorbar to last subplot
    cbar = plt.colorbar(cf, ax=axes, label='HP Viability Score', shrink=0.8)
    
    plt.suptitle('Figure 18: HP Viability Score Contours by Envelope Class\n'
                 f'V = (1 - {alpha:.2f}Â·H*)(1 - {beta:.2f}Â·P*)Â·Î³  |  Bold line: V = 0.5 threshold',
                 fontsize=14, fontweight='bold', y=1.02)
    
    plt.tight_layout()
    plt.savefig(FIGURES_DIR / "Fig18_viability_contours.png", dpi=300, bbox_inches='tight')
    plt.savefig(FIGURES_DIR / "Fig18_viability_contours.pdf", bbox_inches='tight')
    plt.close()
    
    logger.info("  Contour viability plot saved")


def main():
    """Main function"""
    logger.info("=" * 70)
    logger.info("COMPREHENSIVE LIMITATIONS DOCUMENTATION")
    logger.info("=" * 70)
    
    create_limitations_table()
    create_cop_degradation_figure()
    create_aggregation_bias_figure()
    create_monte_carlo_placeholder()
    create_sobol_sensitivity_conceptual()
    create_contour_viability_plot()
    
    logger.info("\n" + "=" * 70)
    logger.info("DOCUMENTATION COMPLETE!")
    logger.info("=" * 70)
    
    print("\nðŸ“ New outputs:")
    print("  âœ… Table10_limitations_summary.csv")
    print("  âœ… Fig14_cop_limitation.png")
    print("  âœ… Fig15_aggregation_bias.png")
    print("  âœ… Fig16_monte_carlo_conceptual.png")
    print("  âœ… Fig17_sobol_conceptual.png")
    print("  âœ… Fig18_viability_contours.png")


if __name__ == "__main__":
    main()
