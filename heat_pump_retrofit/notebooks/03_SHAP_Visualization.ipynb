{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ” SHAP Analysis and Visualization\n",
    "\n",
    "## Interpreting the Thermal Intensity Model\n",
    "\n",
    "**Author:** Fafa (GitHub: Fateme9977)  \n",
    "**Institution:** K. N. Toosi University of Technology\n",
    "\n",
    "---\n",
    "\n",
    "This notebook performs SHAP analysis to interpret the XGBoost thermal intensity model\n",
    "and identify key drivers of heating energy consumption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import shap\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Initialize SHAP\n",
    "shap.initjs()\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "# Project paths\n",
    "PROJECT_ROOT = Path.cwd().parent\n",
    "OUTPUT_DIR = PROJECT_ROOT / 'output'\n",
    "MODELS_DIR = OUTPUT_DIR / 'models'\n",
    "\n",
    "print(f'SHAP version: {shap.__version__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Model and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "model = joblib.load(MODELS_DIR / 'xgboost_thermal_intensity.joblib')\n",
    "encoders = joblib.load(MODELS_DIR / 'label_encoders.joblib')\n",
    "\n",
    "print('Model loaded successfully')\n",
    "print(f'Number of features: {model.n_features_in_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv(OUTPUT_DIR / '03_gas_heated_clean.csv')\n",
    "print(f'Loaded {len(df):,} households')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features (same as training)\n",
    "numeric_features = ['HDD65', 'A_heated', 'building_age', 'log_sqft']\n",
    "categorical_features = ['TYPEHUQ', 'YEARMADERANGE', 'DRAFTY', 'ADQINSUL', \n",
    "                        'TYPEGLASS', 'REGIONC', 'DIVISION', 'envelope_class', 'climate_zone']\n",
    "\n",
    "numeric_features = [f for f in numeric_features if f in df.columns]\n",
    "categorical_features = [f for f in categorical_features if f in df.columns]\n",
    "\n",
    "X = df[numeric_features + categorical_features].copy()\n",
    "\n",
    "# Encode categoricals\n",
    "for col in categorical_features:\n",
    "    if col in encoders:\n",
    "        X[col] = encoders[col].transform(X[col].fillna('missing').astype(str))\n",
    "    elif X[col].dtype == 'object':\n",
    "        X[col] = pd.factorize(X[col].fillna('missing'))[0]\n",
    "    else:\n",
    "        X[col] = X[col].fillna(-1)\n",
    "\n",
    "# Fill numeric NAs\n",
    "for col in numeric_features:\n",
    "    X[col] = X[col].fillna(X[col].median())\n",
    "\n",
    "print(f'Feature matrix shape: {X.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Compute SHAP Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample for SHAP calculation (large datasets can be slow)\n",
    "sample_size = min(2000, len(X))\n",
    "X_sample = X.sample(n=sample_size, random_state=42)\n",
    "\n",
    "print(f'Computing SHAP values for {sample_size} samples...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create SHAP explainer\n",
    "explainer = shap.TreeExplainer(model)\n",
    "\n",
    "# Compute SHAP values\n",
    "shap_values = explainer.shap_values(X_sample)\n",
    "\n",
    "print(f'SHAP values computed. Shape: {shap_values.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Global Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary plot (beeswarm)\n",
    "plt.figure(figsize=(12, 8))\n",
    "shap.summary_plot(shap_values, X_sample, show=False, max_display=15)\n",
    "plt.title('Feature Impact on Thermal Intensity (SHAP Values)', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar plot of mean |SHAP|\n",
    "plt.figure(figsize=(10, 6))\n",
    "shap.summary_plot(shap_values, X_sample, plot_type='bar', show=False, max_display=15)\n",
    "plt.title('Mean |SHAP| - Feature Importance', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table of feature importance\n",
    "mean_abs_shap = np.abs(shap_values).mean(axis=0)\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': X_sample.columns,\n",
    "    'Mean |SHAP|': mean_abs_shap,\n",
    "    'Importance (%)': mean_abs_shap / mean_abs_shap.sum() * 100\n",
    "}).sort_values('Mean |SHAP|', ascending=False)\n",
    "\n",
    "print('Feature Importance Ranking (SHAP):')\n",
    "print(importance_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Dependence Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top features for dependence plots\n",
    "top_features = importance_df.head(6)['Feature'].tolist()\n",
    "print(f'Creating dependence plots for: {top_features}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dependence plots for top features\n",
    "n_plots = min(6, len(top_features))\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, feature in enumerate(top_features[:n_plots]):\n",
    "    plt.sca(axes[i])\n",
    "    feature_idx = list(X_sample.columns).index(feature)\n",
    "    shap.dependence_plot(feature_idx, shap_values, X_sample, show=False, ax=axes[i])\n",
    "    axes[i].set_title(f'SHAP Dependence: {feature}', fontsize=12)\n",
    "\n",
    "# Hide unused axes\n",
    "for i in range(n_plots, len(axes)):\n",
    "    axes[i].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HDD65 dependence with interaction\n",
    "if 'HDD65' in X_sample.columns:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    hdd_idx = list(X_sample.columns).index('HDD65')\n",
    "    \n",
    "    # Auto-detect interaction\n",
    "    shap.dependence_plot(hdd_idx, shap_values, X_sample, show=False)\n",
    "    plt.title('HDD65 Effect on Thermal Intensity', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Individual Explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Waterfall plot for example households\n",
    "\n",
    "# Select example indices (high, medium, low intensity)\n",
    "predictions = model.predict(X_sample)\n",
    "percentiles = [10, 50, 90]  # Low, medium, high\n",
    "\n",
    "for p in percentiles:\n",
    "    threshold = np.percentile(predictions, p)\n",
    "    idx = np.argmin(np.abs(predictions - threshold))\n",
    "    \n",
    "    print(f'\\n=== Example: {p}th percentile prediction ====')\n",
    "    print(f'Predicted value: {predictions[idx]:.2f}')\n",
    "    \n",
    "    # Create explanation\n",
    "    explanation = shap.Explanation(\n",
    "        values=shap_values[idx],\n",
    "        base_values=explainer.expected_value,\n",
    "        data=X_sample.iloc[idx],\n",
    "        feature_names=X_sample.columns.tolist()\n",
    "    )\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    shap.waterfall_plot(explanation, show=False, max_display=10)\n",
    "    plt.title(f'SHAP Waterfall ({p}th percentile)', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Force Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Force plot for single observation\n",
    "idx = 0  # First sample\n",
    "shap.force_plot(\n",
    "    explainer.expected_value,\n",
    "    shap_values[idx],\n",
    "    X_sample.iloc[idx],\n",
    "    matplotlib=True,\n",
    "    show=False\n",
    ")\n",
    "plt.title('SHAP Force Plot - Single Household', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Analysis by Envelope Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare SHAP distributions by envelope class\n",
    "sample_idx = X_sample.index\n",
    "df_sample = df.loc[sample_idx].copy()\n",
    "\n",
    "if 'envelope_class' in df_sample.columns:\n",
    "    # Mean absolute SHAP by envelope class\n",
    "    results = []\n",
    "    \n",
    "    for env_class in ['poor', 'medium', 'good']:\n",
    "        mask = (df_sample['envelope_class'] == env_class).values\n",
    "        if mask.sum() > 10:\n",
    "            class_shap = np.abs(shap_values[mask]).mean(axis=0)\n",
    "            for i, feature in enumerate(X_sample.columns):\n",
    "                results.append({\n",
    "                    'Envelope Class': env_class,\n",
    "                    'Feature': feature,\n",
    "                    'Mean |SHAP|': class_shap[i]\n",
    "                })\n",
    "    \n",
    "    if results:\n",
    "        class_df = pd.DataFrame(results)\n",
    "        pivot = class_df.pivot(index='Feature', columns='Envelope Class', values='Mean |SHAP|')\n",
    "        \n",
    "        # Heatmap\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(pivot, annot=True, fmt='.3f', cmap='YlOrRd')\n",
    "        plt.title('Feature Importance by Envelope Class', fontsize=14)\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Key Physical Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interaction: HDD Ã— Draftiness\n",
    "if 'HDD65' in X_sample.columns and 'DRAFTY' in X_sample.columns:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    hdd_idx = list(X_sample.columns).index('HDD65')\n",
    "    drafty_idx = list(X_sample.columns).index('DRAFTY')\n",
    "    \n",
    "    shap.dependence_plot(\n",
    "        hdd_idx, shap_values, X_sample,\n",
    "        interaction_index=drafty_idx,\n",
    "        show=False\n",
    "    )\n",
    "    plt.title('HDD65 Effect Ã— Draftiness Interaction', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interaction: Building Age Ã— Draftiness\n",
    "if 'building_age' in X_sample.columns and 'DRAFTY' in X_sample.columns:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    age_idx = list(X_sample.columns).index('building_age')\n",
    "    drafty_idx = list(X_sample.columns).index('DRAFTY')\n",
    "    \n",
    "    shap.dependence_plot(\n",
    "        age_idx, shap_values, X_sample,\n",
    "        interaction_index=drafty_idx,\n",
    "        show=False\n",
    "    )\n",
    "    plt.title('Building Age Effect Ã— Draftiness Interaction', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Summary of Key Findings\n",
    "\n",
    "### Top Drivers of Thermal Intensity:\n",
    "1. **Envelope quality (DRAFTY)**: Drafty homes have significantly higher heating intensity\n",
    "2. **Climate (HDD65)**: More heating needed in colder climates, but intensity normalized by HDD\n",
    "3. **Building age**: Older homes tend to have higher intensity due to envelope degradation\n",
    "4. **Floor area**: Larger homes may have different surface-to-volume ratios\n",
    "\n",
    "### Key Interactions:\n",
    "- HDD Ã— Draftiness: Drafty homes suffer more in cold climates\n",
    "- Age Ã— Draftiness: Older drafty homes are the worst performers\n",
    "\n",
    "### Implications for Retrofit:\n",
    "- Air sealing (reducing draftiness) is highly impactful\n",
    "- Older homes in cold climates are priority targets\n",
    "- Envelope quality improvement reduces heating intensity substantially"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save summary\n",
    "importance_df.to_csv(OUTPUT_DIR / 'tables' / 'shap_feature_importance_notebook.csv', index=False)\n",
    "print('Results saved!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
