
================================================================================
DETAILED METHODOLOGY DOCUMENTATION
For Applied Energy Submission - Reproducibility Supplement
================================================================================

1. OUTLIER IDENTIFICATION AND REMOVAL
=====================================

Outliers were identified using the Interquartile Range (IQR) method:

```python
# Pseudocode for outlier removal
def remove_outliers(df, column='thermal_intensity', factor=2.5):
    Q1 = df[column].quantile(0.25)
    Q3 = df[column].quantile(0.75)
    IQR = Q3 - Q1
    
    lower_bound = Q1 - factor * IQR
    upper_bound = Q3 + factor * IQR
    
    # Alternative: percentile-based (used in final analysis)
    lower_bound = df[column].quantile(0.02)  # 2nd percentile
    upper_bound = df[column].quantile(0.98)  # 98th percentile
    
    df_clean = df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]
    return df_clean
```

Applied thresholds:
- Thermal intensity: 0.0004 < I < 0.020 BTU/sqft/HDD
- Removed: ~400 records (4% of sample)
- Reason: Extreme values likely represent data entry errors, 
          vacant homes, or non-typical heating patterns

================================================================================

2. ENVELOPE CLASS DEFINITIONS
=============================

Envelope classes are defined using a composite score based on RECS variables:

```python
def create_envelope_class(df):
    # DRAFTY: 1=Never, 2=Some of the time, 3=Most of the time, 4=All the time
    # ADQINSUL: 1=Well insulated, 2=Adequately, 3=Poorly, 4=No insulation
    
    # Numeric scores (higher = worse envelope)
    drafty_score = df['DRAFTY'].fillna(2)  # Default: some
    insul_score = df['ADQINSUL'].fillna(2)  # Default: adequate
    
    # Composite score (weighted average)
    composite = (0.6 * drafty_score + 0.4 * insul_score)
    
    # Classification thresholds
    df['envelope_class'] = pd.cut(
        composite,
        bins=[0, 1.8, 2.8, 5],
        labels=['Good', 'Medium', 'Poor']
    )
    return df
```

Threshold justification:
- Good (score < 1.8): DRAFTY ≤ 2 AND ADQINSUL ≤ 2
- Medium (1.8 ≤ score < 2.8): Mixed characteristics
- Poor (score ≥ 2.8): DRAFTY ≥ 3 OR ADQINSUL ≥ 3

Resulting distribution (weighted):
- Poor: ~11% of gas-heated stock
- Medium: ~62%
- Good: ~27%

================================================================================

3. XGBOOST FEATURE SELECTION
============================

Feature selection followed a systematic process:

Step 1: Initial feature pool (n=30 variables from RECS codebook)
Step 2: Remove high-missing variables (>20% missing)
Step 3: Remove highly correlated pairs (|r| > 0.85)
Step 4: Preliminary XGBoost with all features
Step 5: SHAP-based importance ranking
Step 6: Remove features with mean|SHAP| < 0.0001
Step 7: Cross-validation to confirm no overfitting

```python
# Feature selection pseudocode
from sklearn.feature_selection import mutual_info_regression

def select_features(X, y, threshold=0.01):
    # Step 1: Mutual information filter
    mi_scores = mutual_info_regression(X, y)
    selected = X.columns[mi_scores > threshold]
    
    # Step 2: Correlation filter
    corr_matrix = X[selected].corr().abs()
    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))
    to_drop = [col for col in upper.columns if any(upper[col] > 0.85)]
    selected = [c for c in selected if c not in to_drop]
    
    # Step 3: SHAP-based refinement (after initial model)
    # ... (see main code)
    
    return selected
```

Final feature set (n=18):
- Numeric: HDD65, A_heated, building_age, log_sqft, log_hdd, 
           hdd_sqft, age_hdd, sqft_sq, hdd_sq, sqft_per_hdd,
           envelope_score, cold_climate, mild_climate
- Categorical (encoded): TYPEHUQ, DRAFTY, REGIONC, ADQINSUL

================================================================================

4. VIABILITY SCORE CALIBRATION
==============================

The viability score V = (1 - α·H*)(1 - β·P*)·γ was calibrated using
nonlinear least squares regression on Pareto analysis results.

```python
from scipy.optimize import minimize

def calibrate_viability_score(pareto_results):
    '''
    pareto_results: DataFrame with columns
        - HDD: Heating degree days
        - price: Electricity price ($/kWh)
        - envelope: 'Poor', 'Medium', 'Good'
        - viable: Binary/continuous viability from Pareto analysis
    '''
    
    # Normalize inputs
    H_star = (pareto_results['HDD'] - 2000) / 6000
    P_star = (pareto_results['price'] - 0.08) / 0.14
    gamma = pareto_results['envelope'].map({'Poor': 1.0, 'Medium': 0.7, 'Good': 0.4})
    
    def objective(params):
        alpha, beta = params
        V_pred = (1 - alpha * H_star) * (1 - beta * P_star) * gamma
        V_actual = pareto_results['viable']
        return np.mean((V_pred - V_actual) ** 2)
    
    result = minimize(objective, x0=[0.5, 0.5], bounds=[(0.1, 1.0), (0.1, 1.0)])
    
    alpha_opt, beta_opt = result.x
    return alpha_opt, beta_opt

# Results from calibration:
# α = 0.58 (95% CI: 0.52-0.64) - Climate sensitivity
# β = 0.79 (95% CI: 0.71-0.87) - Price sensitivity
# Calibration R² = 0.847
```

Bootstrap confidence intervals (1000 iterations):
- α: 0.58 ± 0.06 (SE)
- β: 0.79 ± 0.08 (SE)

Interpretation:
- β > α indicates price has stronger effect on viability
- This aligns with sensitivity analysis (Fig. 11)

================================================================================

5. LIMITATIONS STATEMENT
========================

Key limitations of this study:

1. TEMPORAL RESOLUTION
   - Analysis uses annual HDD data, not hourly
   - COP degradation at low temperatures not modeled dynamically
   - May underestimate cold climate challenges
   - Hourly load matching (grid timing) not considered

2. SPATIAL AGGREGATION
   - HDD data at Census division level
   - Local climate variability within divisions not captured
   - Urban heat island effects not modeled

3. RETROFIT EFFECTIVENESS
   - Uniform percentage reduction assumed
   - Actual effectiveness varies by:
     * Building vintage
     * Construction type
     * Existing insulation levels
     * Installation quality
   - Field validation against monitored data needed

4. EMISSIONS ACCOUNTING
   - Direct combustion emissions only
   - Upstream methane leakage not included (~2-3% of gas supply)
   - Refrigerant GWP from HPs not included
   - Grid emissions use annual average, not marginal

5. UNCERTAINTY PROPAGATION
   - No Monte Carlo analysis performed
   - Single-point sensitivity only
   - Correlated uncertainties not modeled

6. BEHAVIORAL FACTORS
   - Thermostat setpoints assumed constant
   - Rebound effects not modeled
   - Occupant-HP interaction not considered

================================================================================

6. DATA AVAILABILITY
====================

All data used in this analysis are publicly available:

Primary data:
- RECS 2020 Microdata: https://www.eia.gov/consumption/residential/data/2020/
- File: recs2020_public_v7.csv

Validation data:
- Housing Characteristics Tables (HC2.x, HC6.x, HC10.x)
- Consumption & Expenditures Tables

Code availability:
- Analysis code will be deposited at: [repository URL]
- Python 3.10+ required
- Key packages: pandas, numpy, xgboost, shap, scipy, matplotlib

================================================================================
